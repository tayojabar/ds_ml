{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP with Keras using Reuters dataset.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.5 with Spark 2.1",
      "name": "python3-spark21",
      "language": "python"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ubVpInaJAtRI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pip\n",
        "\n",
        "try:\n",
        "    __import__('keras')\n",
        "except ImportError:\n",
        "    pip.main(['install', 'keras']) \n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "seed = 1337\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WeCU_JhAtRQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "max_words = 1000\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=seed)\n",
        "num_classes = np.max(y_train) + 1  # 46 topics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1tYYb9MCAtRY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3j-LikPAtRp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwaoBi09AtRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(max_words,))) # Add first layer. Make sure to specify input shape\n",
        "model.add(Dropout(0.5)) # Add second layer\n",
        "model.add(Dense(num_classes, activation='softmax')) # Add third layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYx2F9jxAtR3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RCZpBT5MAtR8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5DVClDUvAtSD",
        "colab_type": "code",
        "colab": {},
        "outputId": "a08af1fe-60b5-4036-cb52-a064c11b6ab2"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, \n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/5\n",
            "8982/8982 [==============================] - 3s - loss: 1.3912 - acc: 0.6919 - val_loss: 0.9726 - val_acc: 0.7760\n",
            "Epoch 2/5\n",
            "8982/8982 [==============================] - 3s - loss: 0.7723 - acc: 0.8174 - val_loss: 0.8234 - val_acc: 0.8103\n",
            "Epoch 3/5\n",
            "8982/8982 [==============================] - 3s - loss: 0.5552 - acc: 0.8663 - val_loss: 0.8236 - val_acc: 0.8117\n",
            "Epoch 4/5\n",
            "8982/8982 [==============================] - 3s - loss: 0.4231 - acc: 0.8931 - val_loss: 0.8324 - val_acc: 0.8005\n",
            "Epoch 5/5\n",
            "8982/8982 [==============================] - 3s - loss: 0.3488 - acc: 0.9106 - val_loss: 0.8638 - val_acc: 0.8037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OoKPc7qhAtSK",
        "colab_type": "code",
        "colab": {},
        "outputId": "02e815ae-ff59-45f8-ee08-a6080e25713e"
      },
      "cell_type": "code",
      "source": [
        "score[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.80365093499554763"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}