{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shake_classification (1).ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.5 with Spark 2.1",
      "name": "python3-spark21",
      "language": "python"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "8VzhQSeW5AvU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook pulls IoT data (Device Shakes) from an IBM cloud database instance and classifies the data. Vector Assembler is used to create a single feature from multiple features and the GBTClassifier is used for classification (Supervised Learning)"
      ]
    },
    {
      "metadata": {
        "id": "7uu5e90Q5AvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define the credentials to the Cloudant Instance\n",
        "credentials_2 = {\n",
        "  'password':\"\"\"d8f3b5450d8851eeeb421613929f1013a605e6823d0bdb6cc40ca27553a4d958\"\"\",\n",
        "  'custom_url':'https://54fbff02-a585-44c5-a93d-1cc831fa4e02-bluemix:d8f3b5450d8851eeeb421613929f1013a605e6823d0bdb6cc40ca27553a4d958@54fbff02-a585-44c5-a93d-1cc831fa4e02-bluemix.cloudantnosqldb.appdomain.cloud',\n",
        "  'username':'54fbff02-a585-44c5-a93d-1cc831fa4e02-bluemix',\n",
        "  'url':'https://undefined'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUtADPM85Ave",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's create a SparkSession object and put the Cloudant credentials into it"
      ]
    },
    {
      "metadata": {
        "id": "eSiT_d-X5Avg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Define an ApacheSpark session in order to establish connection to the cloudant instance using the credentials defined\n",
        "spark = SparkSession\\\n",
        "    .builder\\\n",
        "    .appName(\"Cloudant Spark SQL Example in Python using temp tables\")\\\n",
        "    .config(\"cloudant.host\",credentials_2['custom_url'].split('@')[1])\\\n",
        "    .config(\"cloudant.username\", credentials_2['username'])\\\n",
        "    .config(\"cloudant.password\",credentials_2['password'])\\\n",
        "    .config(\"jsonstore.rdd.partitions\", 1)\\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ecHD5sKn5Avm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "View the recorded sensor data. "
      ]
    },
    {
      "metadata": {
        "id": "XcuF-_L55Avo",
        "colab_type": "code",
        "outputId": "99e146b1-5578-4d80-81a4-1b088ca5dafa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=spark.read.load('shake_classification', \"com.cloudant.spark\")\n",
        "\n",
        "df.createOrReplaceTempView(\"df\")\n",
        "spark.sql(\"SELECT * from df\").show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------+-----+-----+-----+--------------------+--------------------+\n",
            "|CLASS|SENSORID|    X|    Y|    Z|                 _id|                _rev|\n",
            "+-----+--------+-----+-----+-----+--------------------+--------------------+\n",
            "|    0|asdfghjk|  0.0|  0.0|  0.0|0a9b38684ae98e089...|1-461daac6b553896...|\n",
            "|    0|asdfghjk|  0.0|  0.0|  0.0|0a9b38684ae98e089...|1-461daac6b553896...|\n",
            "|    0|asdfghjk|  0.0|  0.0|  0.0|0a9b38684ae98e089...|1-461daac6b553896...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|\n",
            "|    0|asdfghjk| 1.16| 1.16| 1.16|0a9b38684ae98e089...|1-d2b9fb4163bcde3...|\n",
            "|    0|asdfghjk|-3.01|-3.01|-3.01|0a9b38684ae98e089...|1-e69fb4a4b44ebb9...|\n",
            "|    0|asdfghjk|-1.34|-1.34|-1.34|0a9b38684ae98e089...|1-b7a74f038247bd0...|\n",
            "|    0|asdfghjk|-1.04|-1.04|-1.04|0a9b38684ae98e089...|1-77aa23cfe009cb1...|\n",
            "|    0|asdfghjk|-0.47|-0.47|-0.47|0a9b38684ae98e089...|1-fac9b17ffe87279...|\n",
            "|    0|asdfghjk|-0.07|-0.07|-0.07|0a9b38684ae98e089...|1-63ba1a78225108c...|\n",
            "|    0|asdfghjk|-0.17|-0.17|-0.17|0a9b38684ae98e089...|1-10eaed46699489c...|\n",
            "|    0|asdfghjk| 0.06| 0.06| 0.06|0a9b38684ae98e089...|1-b0e0ea0b0976f0b...|\n",
            "+-----+--------+-----+-----+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rBGYK_vp5Avx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "vectorAssembler = VectorAssembler(inputCols=['X', 'Y', 'Z'], outputCol=\"features\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P5Tx-ov05Av2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "classifier = GBTClassifier(labelCol='CLASS', featuresCol = 'features', maxIter = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LsLxqtrr5Av5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[vectorAssembler, classifier])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bX2HSwrW5Av8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUM-6uXz5AwA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction = model.transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WuCzV3Kd5AwC",
        "colab_type": "code",
        "outputId": "7a726217-5bfd-45c5-cf14-ac93484401be",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------+-----+-----+-----+--------------------+--------------------+-------------------+----------+\n",
            "|CLASS|SENSORID|    X|    Y|    Z|                 _id|                _rev|           features|prediction|\n",
            "+-----+--------+-----+-----+-----+--------------------+--------------------+-------------------+----------+\n",
            "|    0|asdfghjk|  0.0|  0.0|  0.0|0a9b38684ae98e089...|1-461daac6b553896...|          (3,[],[])|       0.0|\n",
            "|    0|asdfghjk|  0.0|  0.0|  0.0|0a9b38684ae98e089...|1-461daac6b553896...|          (3,[],[])|       0.0|\n",
            "|    0|asdfghjk|  0.0|  0.0|  0.0|0a9b38684ae98e089...|1-461daac6b553896...|          (3,[],[])|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 0.38| 0.38| 0.38|0a9b38684ae98e089...|1-c5e0fdd38c44f0b...|   [0.38,0.38,0.38]|       0.0|\n",
            "|    0|asdfghjk| 1.16| 1.16| 1.16|0a9b38684ae98e089...|1-d2b9fb4163bcde3...|   [1.16,1.16,1.16]|       0.0|\n",
            "|    0|asdfghjk|-3.01|-3.01|-3.01|0a9b38684ae98e089...|1-e69fb4a4b44ebb9...|[-3.01,-3.01,-3.01]|       0.0|\n",
            "|    0|asdfghjk|-1.34|-1.34|-1.34|0a9b38684ae98e089...|1-b7a74f038247bd0...|[-1.34,-1.34,-1.34]|       0.0|\n",
            "|    0|asdfghjk|-1.04|-1.04|-1.04|0a9b38684ae98e089...|1-77aa23cfe009cb1...|[-1.04,-1.04,-1.04]|       0.0|\n",
            "|    0|asdfghjk|-0.47|-0.47|-0.47|0a9b38684ae98e089...|1-fac9b17ffe87279...|[-0.47,-0.47,-0.47]|       0.0|\n",
            "|    0|asdfghjk|-0.07|-0.07|-0.07|0a9b38684ae98e089...|1-63ba1a78225108c...|[-0.07,-0.07,-0.07]|       0.0|\n",
            "|    0|asdfghjk|-0.17|-0.17|-0.17|0a9b38684ae98e089...|1-10eaed46699489c...|[-0.17,-0.17,-0.17]|       0.0|\n",
            "|    0|asdfghjk| 0.06| 0.06| 0.06|0a9b38684ae98e089...|1-b0e0ea0b0976f0b...|   [0.06,0.06,0.06]|       0.0|\n",
            "+-----+--------+-----+-----+-----+--------------------+--------------------+-------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hRwcqb775AwG",
        "colab_type": "code",
        "outputId": "b703647b-91f2-4f7c-9ee2-f82a48eb6d24",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "binEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"CLASS\")\n",
        "    \n",
        "binEval.evaluate(prediction) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}